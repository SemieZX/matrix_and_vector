{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import spectral\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_hpi(input_image, dimension=30):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    ## 降维\n",
    "    pca = PCA(n_components=dimension)\n",
    "    pca.fit(spectral_array)\n",
    "    pca_input_iamge = pca.transform(spectral_array)\n",
    "    ## 姜维之后恢复 原来形状\n",
    "    pca_return_array = np.vsplit(pca_input_iamge,input_image.shape[0])\n",
    "    pca_return_array = np.array(pca_return_array)\n",
    "    #print (pca.explained_variance_ratio_)\n",
    "    return pca_return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(A):\n",
    "    A_c = A.transpose(2,1,0)\n",
    "    A_c = A_c.transpose(0,2,1)\n",
    "    return A_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以提取出高光谱数据的一个channel的数据 145*145\n",
    "# 注意这里输入转换坐标后的矩阵\n",
    "def split_one_channel(A,channel):\n",
    "    return A[channel-1] \n",
    "# 参数说明\n",
    "# channel 通道\n",
    "# A 高光谱立方块\n",
    "\n",
    "# 依据patch大小（Filter 大小）对矩阵进行镜像处理\n",
    "def mirror_matrix(A, fil):\n",
    "    pad = int((fil-1)/2)\n",
    "    for  i in range(1,pad+1):\n",
    "        up = np.array(A[2*i-1,:])\n",
    "        down = np.array(A[-2*i,:])\n",
    "        Matrix_up_down = np.vstack([up,A,down])\n",
    "        left = np.array(Matrix_up_down[:,2*i-1]).reshape(len(Matrix_up_down),1)\n",
    "        right = np.array(Matrix_up_down[:,-2*i]).reshape(len(Matrix_up_down),1)\n",
    "        Matrix_left_right = np.hstack([left,Matrix_up_down,right,])\n",
    "        A = Matrix_left_right\n",
    "    return A\n",
    "\n",
    "# 参数说明\n",
    "# n   array size\n",
    "# fil  filter size5*5\n",
    "# pad = (fil-1)/2  padding大小\n",
    "\n",
    "\n",
    "# 将镜像处理后的矩阵进行向量化操作\n",
    "def split_array(A,fil):\n",
    "    s = []\n",
    "    row = len(A)-fil+1\n",
    "    col = len(A[0])-fil+1\n",
    "    for i in range(row): # row\n",
    "        for j in range(col): # col\n",
    "            temp = [0]* fil\n",
    "            for z in range(fil):\n",
    "                temp[z] = A[i+z,j:j+fil]\n",
    "            com = np.concatenate(temp)\n",
    "            s.append(com)\n",
    "    return s \n",
    "# 参数说明\n",
    "# A 镜像处理后的矩阵\n",
    "# fil  filter size\n",
    "\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def Euclidean(v1,v2):\n",
    "    return np.linalg.norm(v1-v2)\n",
    "\n",
    "\n",
    "# 计算单个patch的空间信息\n",
    "def patch_spitial(v1, K_centroid):\n",
    "    distance_array = np.array([Euclidean(v1, centroid) for centroid in K_centroid]) #距离matrix\n",
    "    sums = np.sum(distance_array)\n",
    "    average = np.average(distance_array)\n",
    "    spitial_one_patch = np.maximum(0,average - distance_array) #依据公式求空间信息\n",
    "    return spitial_one_patch\n",
    "\n",
    "# 对一个channel的求解进行向量化\n",
    "def channel_spitial(channel_matrix, K_centroid):\n",
    "    channel_spitial_list = list()\n",
    "    for i in range(len(channel_matrix)):\n",
    "        channel_spitial_list.append(patch_spitial(channel_matrix[i], K_centroid))\n",
    "    return np.array(channel_spitial_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造n个通道的向量 输入转换坐标后的矩阵\n",
    "def create_whole_vector(dim,fil,input_image):\n",
    "    # 生成器\n",
    "    pad =int((fil-1)/2)\n",
    "    s = (split_one_channel(input_image,i) for i in range(1,dim+1))\n",
    "    whole_origin_matrix_array = np.array(next(s))\n",
    "    while True:\n",
    "        try:\n",
    "            whole_origin_matrix_array = np.vstack((whole_origin_matrix_array,next(s)))\n",
    "        except StopIteration as e:\n",
    "            whole_origin_matrix_array = whole_origin_matrix_array.reshape(dim,input_image.shape[1],\n",
    "                                                                          input_image.shape[2])                                                                     \n",
    "            break\n",
    "    p = (mirror_matrix(whole_origin_matrix_array[i],fil) for i in range(dim))\n",
    "    whole_mirror_matrix_array = np.array(next(p))\n",
    "    while True:\n",
    "        try:\n",
    "            whole_mirror_matrix_array = np.vstack((whole_mirror_matrix_array, next(p)))\n",
    "        except StopIteration as e:\n",
    "            whole_mirror_matrix_array = whole_mirror_matrix_array.reshape(dim,input_image.shape[1]+pad*2,\n",
    "                                                                          input_image.shape[2]+pad*2)\n",
    "            break\n",
    "    t = (split_array(whole_mirror_matrix_array[i],fil) for i in range(dim))\n",
    "    whole_split_matrix_array = np.array(next(t))\n",
    "    while True:\n",
    "        try:\n",
    "            whole_split_matrix_array = np.vstack((whole_split_matrix_array, next(t)))\n",
    "        except StopIteration as e:\n",
    "            whole_split_matrix_array = whole_split_matrix_array.reshape(dim,input_image.shape[1]*input_image.shape[2],-1)\n",
    "            break\n",
    "    return  whole_split_matrix_array\n",
    "\n",
    "\n",
    "\n",
    "## 通过k-means求解 whole_K_centroid\n",
    "K = 5\n",
    "def create_centroid(K,dim,whole_split_matrix_array):\n",
    "    whole_kmeans = [KMeans(n_clusters=K, random_state=0).fit(whole_split_matrix_array[i]) for i in range(dim)] \n",
    "    t = (whole_kmeans[i].cluster_centers_ for i in range(dim))\n",
    "    whole_K_centroid = np.array(next(t))\n",
    "    while True:\n",
    "        try:\n",
    "            whole_K_centroid = np.vstack((whole_K_centroid,next(t)))\n",
    "        except StopIteration as e:\n",
    "            whole_K_centroid = whole_K_centroid.reshape(dim,K,-1)\n",
    "            break\n",
    "    \n",
    "    return whole_K_centroid\n",
    "\n",
    "## 求整体空间信息\n",
    "def create_spe_spi(whole_K_centroid,whole_split_matrix_array,dim):\n",
    "    g = (channel_spitial(whole_split_matrix_array[i], whole_K_centroid[i])for i in range(whole_K_centroid.shape[0]))\n",
    "    whole_spitial  = np.array(next(g))\n",
    "    while True:\n",
    "        try:\n",
    "            whole_spitial = np.vstack((whole_spitial, next(g)))\n",
    "        except StopIteration as e:\n",
    "            whole_spitial = whole_spitial.reshape(dim,whole_split_matrix_array.shape[1],-1)\n",
    "            break\n",
    "    return whole_spitial\n",
    "\n",
    "###### 可选操作，将spectral-spitial信息以numpy形式保存\n",
    "def save_spe_spi(whole_spitial,path='I:\\data\\whole_spitial.npy'):\n",
    "    np.save(path,whole_spitial)\n",
    "###### 可选操作，载入数据\n",
    "def load_spe_spi(name):\n",
    "    s = np.load(name)\n",
    "    return s\n",
    "\n",
    "## 合成sample_with_lables\n",
    "def sample_with_lables(s,dim,output_image):\n",
    "    sample = np.hstack([s[i]for i in range(dim)])\n",
    "    label = output_image.reshape(len(sample),1)\n",
    "    sample_lb = np.hstack([sample,label])\n",
    "    return sample_lb\n",
    "\n",
    "\n",
    "## 提取出需要分类的数据\n",
    "def need_claasify(sample_lb):\n",
    "    sample_lab_fix_list = list()\n",
    "    for i in range(len(sample_lb)):\n",
    "        if sample_lb[i,-1] != 0:\n",
    "            sample_lab_fix_list.append(sample_lb[i,:])\n",
    "    sample_lab_fix = np.array(sample_lab_fix_list)\n",
    "    return sample_lab_fix\n",
    "\n",
    "\n",
    "\n",
    "## 将数据归一化并且存储：\n",
    "def scaler_save(sample_lab_fix, path = 'H:\\data\\spec_spi.csv'):\n",
    "    ## 归一化\n",
    "    data_D = preprocessing.StandardScaler().fit_transform(sample_lab_fix[:,:-1])\n",
    "    data_L = sample_lab_fix[:,-1]\n",
    "\n",
    "    ## 存储\n",
    "    new = np.column_stack((data_D, data_L))\n",
    "    new_ = pd.DataFrame(new)\n",
    "    new_.to_csv(path,header=False,index=False)\n",
    "    \n",
    "\n",
    "## 分类数据提取\n",
    "def classify_pre(path='H:\\data\\spec_spi.csv'):\n",
    "    data = pd.read_csv(path,header=None)\n",
    "    data = data.as_matrix()\n",
    "    data_D = data[:,:-1]\n",
    "    data_L = data[:,-1]\n",
    "    data_train, data_test, label_train, label_test = train_test_split(data_D,data_L,test_size=0.9)\n",
    "    return data_train, data_test, label_train, label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 设置初始值\n",
    "DIM = 30\n",
    "FIL = 50\n",
    "K = 5\n",
    "\n",
    "## 载入数值\n",
    "input_image = loadmat('I:\\data\\Salinas_corrected.mat')['salinas_corrected']\n",
    "output_image = loadmat('I:\\data\\Salinas_gt.mat')['salinas_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 512, 217)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca后 将数据的光谱放到第一维\n",
    "input_image_pca = pca_hpi(input_image, DIM)\n",
    "input_image_pca_trans = trans(input_image_pca)\n",
    "input_image_pca_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-04a6e9f23563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 将数据全部向量化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwhole_split_matrix_array\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcreate_whole_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFIL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_image_pca_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwhole_split_matrix_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f49897e2c581>\u001b[0m in \u001b[0;36mcreate_whole_vector\u001b[1;34m(dim, fil, input_image)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mwhole_split_matrix_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_split_matrix_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mwhole_split_matrix_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_split_matrix_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 将数据全部向量化\n",
    "whole_split_matrix_array =create_whole_vector(DIM,FIL,input_image_pca_trans)\n",
    "whole_split_matrix_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
