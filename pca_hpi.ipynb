{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import spectral\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = loadmat('H:\\data\\hyp_data.mat')['hyp_data']\n",
    "output_image = loadmat('H:\\data\\X.mat')['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 144, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3172, 4142, 4506, 4279, 4782, 5048, 5213, 5106, 5053, 4750, 4816,\n",
       "       4769, 4610, 4805, 4828, 4861, 4767, 4624, 4549, 4463, 4462, 4446,\n",
       "       4445, 4336, 4381, 4319, 4207, 4305, 4311, 3991, 4168, 3942, 4061,\n",
       "       4365, 4318, 4252, 4869, 5284, 5055, 3591, 5175, 5217, 5058, 4969,\n",
       "       4721, 4291, 4555, 4886, 4868, 4806, 4783, 4811, 4709, 3903, 3795,\n",
       "       3715, 3359, 2130, 2269, 2480, 3145, 3626, 4060, 4296, 4211, 4225,\n",
       "       4157, 4133, 4082, 4048, 3935, 3843, 3784, 3642, 3271, 2707, 1707,\n",
       "       1564, 1838, 1719, 2229, 2764, 2919, 2873, 2977, 2913, 3034, 3051,\n",
       "       3124, 3101, 3033, 2713, 2740, 2947, 2706, 2834, 2856, 2683, 2400,\n",
       "       2229, 1822, 1542, 1097, 1047, 1069, 1100, 1122, 1259, 1365, 1261,\n",
       "       1374, 1630, 1851, 2028, 2130, 2170, 2205, 2214, 2204, 2100, 2106,\n",
       "       2146, 2089, 2078, 2134, 2127, 2074, 2057, 2045, 2003, 1999, 1959,\n",
       "       1924, 1883, 1843, 1781, 1716, 1698, 1645, 1540, 1410, 1294, 1131,\n",
       "       1044, 1032, 1045, 1100, 1212, 1295, 1244, 1100, 1103, 1216, 1346,\n",
       "       1330, 1259, 1251, 1313, 1372, 1393, 1402, 1396, 1381, 1396, 1381,\n",
       "       1353, 1346, 1341, 1332, 1324, 1310, 1318, 1330, 1310, 1292, 1280,\n",
       "       1275, 1266, 1264, 1233, 1241, 1232, 1215, 1215, 1187, 1168, 1171,\n",
       "       1150, 1134, 1123, 1135, 1094, 1090, 1112, 1090, 1062, 1069, 1057,\n",
       "       1020, 1020], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image[0][0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image[0][143,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral = list()\n",
    "for i in range(input_image.shape[0]):\n",
    "    for j in range(input_image.shape[1]):\n",
    "        spectral.append(input_image[i][j,])\n",
    "spectral_array = np.array(spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20736, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=30, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(spectral_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_iamge = pca.transform(spectral_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([725533.17658989, 422920.09519002, 112020.64143512,  51443.86345089,\n",
       "        37821.62168121,  33253.2359909 ,  23200.28001581,  16810.66107045,\n",
       "        16167.06514897,  13138.87550709,  11897.31170378,  10975.55839113,\n",
       "        10241.67867677,   8096.56704771,   7941.52624596,   7498.19566705,\n",
       "         7312.96286756,   6856.05559166,   6564.25686992,   6209.17886393,\n",
       "         6082.79281997,   5993.76680611,   5760.56121782,   5640.72198473,\n",
       "         5593.57205227,   5517.90156429,   5386.02186576,   5330.09203276,\n",
       "         5238.25965562,   5167.68884381])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.25040461e-01, 2.46356675e-01, 1.72839818e-02, 3.64514530e-03,\n",
       "       1.97028016e-03, 1.52305476e-03, 7.41368525e-04, 3.89239831e-04,\n",
       "       3.60006272e-04, 2.37773848e-04, 1.94959935e-04, 1.65920841e-04,\n",
       "       1.44474095e-04, 9.02920522e-05, 8.68671637e-05, 7.74392662e-05,\n",
       "       7.36604601e-05, 6.47435265e-05, 5.93497406e-05, 5.31026301e-05,\n",
       "       5.09628539e-05, 4.94820148e-05, 4.57064281e-05, 4.38245112e-05,\n",
       "       4.30949285e-05, 4.19368289e-05, 3.99561758e-05, 3.91306540e-05,\n",
       "       3.77939022e-05, 3.67824288e-05])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20736, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_input_iamge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5310.14504592, -1874.08190525,   532.9421584 ,  -180.18950009,\n",
       "         136.78141482,  -168.41546566,    95.28565953,    13.93525059,\n",
       "           6.87576673,    -7.35003781,    21.69726012,    59.20058991,\n",
       "          44.01497852,  -116.80147124,   -83.60287417,   -45.0078664 ,\n",
       "           6.94458093,   -36.40291763,    17.79792474,    41.72823264,\n",
       "         -39.25229262,    23.7429987 ,    -6.16167569,    21.93371329,\n",
       "          23.23181569,   -39.26856233,    46.03490913,   -17.6815108 ,\n",
       "          -7.69952826,   -55.49570591])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_input_iamge[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以提取出高光谱数据的一个channel的数据 144*144\n",
    "def split_one_channel(A ,channel):\n",
    "    d = [0]*144\n",
    "    for i in range(144):\n",
    "        d[i] = input_image[i][:,channel-1]\n",
    "    e = np.vstack((d[i] for i in range(144)))\n",
    "    return e  \n",
    "# 参数说明\n",
    "# channel 通道\n",
    "# A 高光谱立方块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image[0][:,0]\n",
    "input_image[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list()\n",
    "for i in range(144):\n",
    "    d.append(input_image[i][:,0])\n",
    "d_arr = np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = split_one_channel(input_image,1)\n",
    "type(d_arr)\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维后的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_iamge = pca.transform(spectral_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_iamge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_iamge[20735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_return_array_one = np.vstack([pca_input_iamge[0:144]])\n",
    "# pca_return_array = list()\n",
    "# pca_return_array.ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意vstcak分割的用法\n",
    "pca_return_array = np.vsplit(pca_input_iamge,144)\n",
    "pca_return_array = np.array(pca_return_array) ########## ￥￥￥￥￥￥￥￥￥￥￥￥￥处理完后的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_return_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_return_array[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "144*144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整体操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import spectral\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = loadmat('H:\\data\\hyp_data.mat')['hyp_data']\n",
    "output_image = loadmat('H:\\data\\X.mat')['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA降维操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_hpi(input_image, dimension=30):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    ## 降维\n",
    "    pca = PCA(n_components=dimension)\n",
    "    pca.fit(spectral_array)\n",
    "    pca_input_iamge = pca.transform(spectral_array)\n",
    "    ## 姜维之后恢复 原来形状\n",
    "    pca_return_array = np.vsplit(pca_input_iamge,144)\n",
    "    pca_return_array = np.array(pca_return_array)\n",
    "    print (pca.explained_variance_ratio_)\n",
    "    return pca_return_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取一个channel的空间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以提取出高光谱数据的一个channel的数据 144*144\n",
    "def split_one_channel(A,channel):\n",
    "    d = [0]*144\n",
    "    for i in range(144):\n",
    "        d[i] = A[i][:,channel-1]\n",
    "    e = np.vstack((d[i] for i in range(144)))\n",
    "    return e  \n",
    "# 参数说明\n",
    "# channel 通道\n",
    "# A 高光谱立方块\n",
    "\n",
    "\n",
    "# 依据patch大小（Filter 大小）对矩阵进行镜像处理\n",
    "def mirror_matrix(A, fil):\n",
    "    pad = int((fil-1)/2)\n",
    "    for  i in range(1,pad+1):\n",
    "        up = np.array(A[2*i-1,:])\n",
    "        down = np.array(A[-2*i,:])\n",
    "        Matrix_up_down = np.vstack([up,A,down])\n",
    "        left = np.array(Matrix_up_down[:,2*i-1]).reshape(len(Matrix_up_down),1)\n",
    "        right = np.array(Matrix_up_down[:,-2*i]).reshape(len(Matrix_up_down),1)\n",
    "        Matrix_left_right = np.hstack([left,Matrix_up_down,right,])\n",
    "        A = Matrix_left_right\n",
    "    return A\n",
    "\n",
    "# 参数说明\n",
    "# n   array size\n",
    "# fil  filter size5*5\n",
    "# pad = (fil-1)/2  padding大小\n",
    "\n",
    "\n",
    "# 将镜像处理后的矩阵进行向量化操作\n",
    "def split_array(A,fil):\n",
    "    s = []\n",
    "    length = len(A)-fil+1\n",
    "    for i in range(length): # row\n",
    "        for j in range(length): # col\n",
    "            temp = [0]* fil\n",
    "            for z in range(fil):\n",
    "                temp[z] = A[i+z,j:j+fil]\n",
    "            com = np.concatenate([item for item in temp ])\n",
    "            s.append(com)\n",
    "    return s \n",
    "# 参数说明\n",
    "# A 镜像处理后的矩阵\n",
    "# fil  filter size\n",
    "\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def Euclidean(v1,v2):\n",
    "    return np.linalg.norm(v1-v2)\n",
    "\n",
    "\n",
    "# 计算单个patch的空间信息\n",
    "def patch_spitial(v1, K_centroid):\n",
    "    distance_array = np.array([Euclidean(v1, centroid) for centroid in K_centroid]) #距离matrix\n",
    "    sums = np.sum(distance_array)\n",
    "    average = np.average(distance_array)\n",
    "    spitial_one_patch = np.maximum(0,average - distance_array) #依据公式求空间信息\n",
    "    return spitial_one_patch\n",
    "\n",
    "# 对一个channel的求解进行向量化\n",
    "def channel_spitial(channel_matrix, K_centroid):\n",
    "    channel_spitial_list = list()\n",
    "    for i in range(len(channel_matrix)):\n",
    "        channel_spitial_list.append(patch_spitial(channel_matrix[i], K_centroid))\n",
    "    return np.array(channel_spitial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整体求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构造n个通道的向量\n",
    "def create_whole_vector(dim,fil,input_image):\n",
    "    whole_origin_matrix_array = np.array([split_one_channel(input_image,i) for i in range(1,dim+1)])\n",
    "    whole_mirror_matrix_array = np.array([mirror_matrix(whole_origin_matrix_array[i],fil) for i in range(dim)])\n",
    "    whole_split_matrix_array = np.array([split_array(whole_mirror_matrix_array[i],fil) for i in range(dim)])\n",
    "    return whole_split_matrix_array\n",
    "\n",
    "## 通过k-means求解 whole_K_centroid\n",
    "K =5 # K个中心\n",
    "def create_centroid(K,dim,whole_split_matrix_array):\n",
    "    whole_kmeans = [KMeans(n_clusters=K, random_state=0).fit(whole_split_matrix_array[i]) for i in range(dim)]\n",
    "    whole_K_centroid = [whole_kmeans[i].cluster_centers_ for i in range(dim) ]\n",
    "    return whole_K_centroid\n",
    "\n",
    "## 求整体空间信息\n",
    "def create_spe_spi(whole_K_centroid,whole_split_matrix_array):\n",
    "    whole_temp = list()\n",
    "    for i in range(len(whole_K_centroid)):\n",
    "        whole_temp.append(channel_spitial(whole_split_matrix_array[i],whole_K_centroid[i]))\n",
    "    whole_spitial = np.array(whole_temp)\n",
    "    return whole_spitial\n",
    "\n",
    "\n",
    "###### 可选操作，将spectral-spitial信息以numpy形式保存\n",
    "def save_spe_spi(whole_spitial):\n",
    "    np.save(\"whole_spitial.npy\",whole_spitial)\n",
    "###### 可选操作，载入数据\n",
    "def load_spe_spi(name):\n",
    "    s = np.load(name)\n",
    "    return s\n",
    "\n",
    "## 合成sample_with_lables\n",
    "def sample_with_lables(s,dim,output_image):\n",
    "    sample = np.hstack([s[i]for i in range(dim)])\n",
    "    label = output_image.reshape(len(sample),1)\n",
    "    sample_lb = np.hstack([sample,label])\n",
    "    return sample_lb\n",
    "\n",
    "\n",
    "## 提取出需要分类的数据\n",
    "def need_claasify(sample_lb):\n",
    "    sample_lab_fix_list = list()\n",
    "    for i in range(len(sample_lb)):\n",
    "        if sample_lb[i,-1] != 0:\n",
    "            sample_lab_fix_list.append(sample_lb[i,:])\n",
    "    sample_lab_fix = np.array(sample_lab_fix_list)\n",
    "    return sample_lab_fix\n",
    "\n",
    "\n",
    "## 将数据归一化并且存储：\n",
    "def scaler_save(sample_lab_fix, path = 'H:\\data\\spec_spi.csv'):\n",
    "    ## 归一化\n",
    "    data_D = preprocessing.StandardScaler().fit_transform(sample_lab_fix[:,:-1])\n",
    "    data_L = sample_lab_fix[:,-1]\n",
    "\n",
    "    ## 存储\n",
    "    new = np.column_stack((data_D, data_L))\n",
    "    new_ = pd.DataFrame(new)\n",
    "    new_.to_csv(path,header=False,index=False)\n",
    "    \n",
    "\n",
    "## 分类数据提取\n",
    "def classify_pre(path='H:\\data\\spec_spi.csv'):\n",
    "    data = pd.read_csv(path,header=None)\n",
    "    data = data.as_matrix()\n",
    "    data_D = data[:,:-1]\n",
    "    data_L = data[:,-1]\n",
    "    data_train, data_test, label_train, label_test = train_test_split(data_D,data_L,test_size=0.9)\n",
    "    return data_train, data_test, label_train, label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置初始值\n",
    "DIM = 30\n",
    "FIL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.25040461e-01 2.46356675e-01 1.72839818e-02 3.64514530e-03\n",
      " 1.97028016e-03 1.52305476e-03 7.41368525e-04 3.89239831e-04\n",
      " 3.60006272e-04 2.37773848e-04 1.94959934e-04 1.65920845e-04\n",
      " 1.44474087e-04 9.02926205e-05 8.68673915e-05 7.74392631e-05\n",
      " 7.36564768e-05 6.47424790e-05 5.93460400e-05 5.31272071e-05\n",
      " 5.09545156e-05 4.94690855e-05 4.57254339e-05 4.38107329e-05\n",
      " 4.31095498e-05 4.18094715e-05 4.00067181e-05 3.90565962e-05\n",
      " 3.84721533e-05 3.71494110e-05]\n"
     ]
    }
   ],
   "source": [
    "pca_return_array = pca_hpi(input_image,DIM) # 降维操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 144, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_return_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_split_matrix_array = create_whole_vector(DIM,FIL,pca_return_array) ## 对30维高光谱数据进行向量化操作处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20736, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_split_matrix_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_K_centroid = create_centroid(FIL,DIM,whole_split_matrix_array) ## 通过k-means求解空间前置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_K_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_spitial = create_spe_spi(whole_K_centroid,whole_split_matrix_array) # 通过欧几里得距离求解空谱信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20736, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_spitial.shape  # 验证空谱信息提出成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_spe_spi(whole_spitial)   ##将空谱信心保存为numpy格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_spi = load_spe_spi('whole_spitial.npy')  # 将空谱信息载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20736, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_spi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lb = sample_with_lables(spec_spi,DIM,output_image) # 合成带有标签的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20736, 91)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lab_fix = need_claasify(sample_lb) ## 提取需要分类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10366, 91)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lab_fix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_save(sample_lab_fix, path = 'H:\\data\\pca_spec_spic_30.csv') # 归一化后保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = classify_pre(path='H:\\data\\pca_spec_spic_30.csv') #分类前置操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554126473740622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pca_specr_spi_30.m']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = lgb.LGBMClassifier()\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# # clf = XGBClassifier(max_depth=20,learning_rate=0.3,n_estimators=500,silent=False,\n",
    "#                        objective='multi:softmax',\n",
    "#                         min_child_weight=1,\n",
    "#                         gamma=0.,\n",
    "#                         scale_pos_weight=1)\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5,\n",
    "#      max_depth=20, random_state=0)\n",
    "# clf = AdaBoostClassifier(\n",
    "#     SVC(kernel='linear'),\n",
    "#     n_estimators=2,\n",
    "#     learning_rate=1,\n",
    "#     algorithm=\"SAMME\")\n",
    "\n",
    "clf.fit(data_train,label_train)\n",
    "# pred = clf.predict(data_test)\n",
    "# accuracy = metrics.accuracy_score(label_test, pred)*100\n",
    "# print(accuracy)\n",
    "acc = clf.score(data_test, label_test)\n",
    "print(acc)\n",
    "joblib.dump(clf,\"pca_specr_spi_30.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
