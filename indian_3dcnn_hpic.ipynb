{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,ZeroPadding3D\n",
    "from keras.layers import Conv3D,MaxPooling3D, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input : 5x5x200x1 1个channel -> (5,5,200,1)\n",
    "# layers: 20 filters (3,3,3) 只有 3th dimension 进行 same padding\n",
    "model.add(ZeroPadding3D(padding=(0, 0, 1)))\n",
    "model.add(Conv3D(20,(3,3,3),activation='relu',input_shape=(5,5,200,1)))\n",
    "model.add(MaxPooling3D(pool_size=(3,3,1))) # 200\n",
    "\n",
    "# 1D 卷积 input  1x1x200\n",
    "model.add(Conv3D(20,(1,1,3),strides=(1,1,2),padding='same',activation='relu'))\n",
    "#  参数个数为60, 序列成为100\n",
    "model.add(Conv3D(20,(1,1,3),strides=(1,1,2),padding='same',activation='relu'))\n",
    "#  参数个数为60, 序列成为50\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#adam = Adam(lr=1e-4)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 降维操作\n",
    "def pca_hpi(input_image, dimension=30):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    ## 降维\n",
    "    pca = PCA(n_components=dimension,svd_solver='auto')\n",
    "    pca.fit(spectral_array)\n",
    "    pca_input_iamge = pca.transform(spectral_array)\n",
    "    ## 姜维之后恢复 原来形状\n",
    "    pca_return_array = np.vsplit(pca_input_iamge,145)\n",
    "    pca_return_array = np.array(pca_return_array)\n",
    "    print (pca.explained_variance_ratio_)\n",
    "    return pca_return_array\n",
    "  \n",
    "  # 归一化后降维\n",
    "def pca_scal_hpi(input_image, dimension=30):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    spectral_array = preprocessing.scale(spectral_array) # 归一化\n",
    "    pca = PCA(n_components=dimension,svd_solver='auto')\n",
    "    pca.fit(spectral_array)\n",
    "    pca_input_iamge = pca.transform(spectral_array)\n",
    "    ## 姜维之后恢复 原来形状\n",
    "    pca_return_array = np.vsplit(pca_input_iamge,145)\n",
    "    pca_return_array = np.array(pca_return_array)\n",
    "    print (pca.explained_variance_ratio_)\n",
    "    return pca_return_array \n",
    "\n",
    "# pca后降维\n",
    "def pca_scal_hpi(input_image, dimension=30):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    ## 降维\n",
    "    pca = PCA(n_components=dimension,svd_solver='auto')\n",
    "    pca.fit(spectral_array)\n",
    "    pca_input_iamge = pca.transform(spectral_array)\n",
    "    # 归一化操作\n",
    "    pca_input_iamge = preprocessing.scale(pca_input_iamge)\n",
    "    ## 降维之后恢复 原来形状\n",
    "    pca_return_array = np.vsplit(pca_input_iamge,145)\n",
    "    pca_return_array = np.array(pca_return_array)\n",
    "    print (pca.explained_variance_ratio_)\n",
    "    return pca_return_array\n",
    "##### 不降维，进行归一化处理\n",
    "def scaler(input_image):\n",
    "    spectral = list()\n",
    "    for i in range(input_image.shape[0]):\n",
    "        for j in range(input_image.shape[1]):\n",
    "            spectral.append(input_image[i][j,])\n",
    "    spectral_array = np.array(spectral)\n",
    "    spectral_array = preprocessing.scale(spectral_array)\n",
    "    return_array = np.vsplit(spectral_array,145)\n",
    "    return_array = np.array(return_array)\n",
    "    return return_array\n",
    "\n",
    "    \n",
    "#####-------------------------------------------------- 生成 3D Tensor---------------------------########\n",
    "\n",
    "# 可以提取出高光谱数据的一个channel的数据 145*145\n",
    "def split_one_channel(A,channel):\n",
    "    row = A.shape[0]\n",
    "    d = [0]*row\n",
    "    for i in range(row):\n",
    "        d[i] = A[i][:,channel-1]\n",
    "    e = np.vstack((d[i] for i in range(row)))\n",
    "    return e   \n",
    "# 参数说明\n",
    "# channel 通道\n",
    "# A 高光谱立方块\n",
    "\n",
    "\n",
    "# 依据patch大小（Filter 大小）对矩阵进行镜像处理\n",
    "def mirror_matrix(A, fil):\n",
    "    pad = int((fil-1)/2)\n",
    "    for  i in range(1,pad+1):\n",
    "        up = np.array(A[2*i-1,:])\n",
    "        down = np.array(A[-2*i,:])\n",
    "        Matrix_up_down = np.vstack([up,A,down])\n",
    "        left = np.array(Matrix_up_down[:,2*i-1]).reshape(len(Matrix_up_down),1)\n",
    "        right = np.array(Matrix_up_down[:,-2*i]).reshape(len(Matrix_up_down),1)\n",
    "        Matrix_left_right = np.hstack([left,Matrix_up_down,right,])\n",
    "        A = Matrix_left_right\n",
    "    return A\n",
    "\n",
    "# 参数说明\n",
    "# n   array size\n",
    "# fil  filter size5*5\n",
    "# pad = (fil-1)/2  padding大小\n",
    "\n",
    "\n",
    "def recreate_whole_data(dim,fil,input_image):\n",
    "    whole_origin_matrix_array = np.array([split_one_channel(input_image,i) for i in range(1,dim+1)])\n",
    "    whole_mirror_matrix_array = np.array([mirror_matrix(whole_origin_matrix_array[i],fil) for i in range(dim)])\n",
    "    return whole_mirror_matrix_array\n",
    "\n",
    "\n",
    "## 分割patch  work out 一个维度的patch\n",
    "def create_patch_one(A,fil):\n",
    "    whole_arr = list()\n",
    "    row = A.shape[0]-fil+1\n",
    "    column = A.shape[1]-fil+1\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            temp_arr = list()\n",
    "            for z in range(fil):\n",
    "                p = A[i+z,j:j+fil]\n",
    "                temp_arr.append(p)\n",
    "            one_arr = np.vstack(temp_arr)\n",
    "            whole_arr.append(one_arr)\n",
    "    return np.array(whole_arr)\n",
    "    \n",
    "def create_patch_whole(A,fil,dim):\n",
    "    temp = [create_patch_one(split_one_channel(A,i),fil) for i in range(1,dim+1)]\n",
    "    return np.array(temp)\n",
    "\n",
    "\n",
    "def create_patch_cube(patch,fil,dim):\n",
    "    temp = list()\n",
    "    nums = patch[0].shape[0] # the nums of every dim of windows  n - f + 1\n",
    "    for j in range(nums):\n",
    "        temp_re = np.vstack([patch[i][j] for i in range(dim)]).reshape(dim,fil,fil)\n",
    "        temp_re1= temp_re.transpose(2,1,0) # switch 1,3 dim\n",
    "        temp_re2 = temp_re1.transpose(1,0,2) # switch 1,2 dim\n",
    "        temp.append(temp_re2)\n",
    "    patch_cubes = np.array(temp)\n",
    "    return patch_cubes\n",
    "\n",
    "def whole_sample_lable(patch_cubes):\n",
    "    sample_lable_list = list()\n",
    "    for i in range(len(patch_cubes)):\n",
    "            sample_lable_list.append((patch_cubes[i],out_labels[i]))\n",
    "    whole_sample_lable_array = np.array(sample_lable_list)\n",
    "    return whole_sample_lable_array\n",
    "\n",
    "# 提取有用的标签\n",
    "def useful_sample_lable(patch_cubes):\n",
    "    sample_lable_list = list()\n",
    "    for i in range(len(patch_cubes)):\n",
    "        if out_labels[i] != 0:\n",
    "            sample_lable_list.append((patch_cubes[i],out_labels[i]))\n",
    "    sample_lable_array = np.array(sample_lable_list)\n",
    "    return sample_lable_array\n",
    "\n",
    "  \n",
    "# 存储numpy文件\n",
    "def save_sample_label(sample_lable_array,path='H:\\data\\sample_lable_array'):\n",
    "    np.save(path,sample_lable_array)\n",
    "    \n",
    "# 载入numpy文件\n",
    "def load_sample_label(name):\n",
    "    s = np.load(name)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 200\n",
    "FIL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = loadmat('F:\\data\\Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "out = loadmat('F:\\data\\Indian_pines_gt.mat')['indian_pines_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint16 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "return_array_alpha = scaler(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 145, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_array_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_array_beta = recreate_whole_data(DIM,FIL,return_array_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 149, 149)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_array_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_array_beta = return_array_beta.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 149, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_array_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_array_beta=return_array_beta.transpose(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 149, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_array_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## 将每个 filxfil (5x5)的patch取出来， 并将每个channel的信息放入一个集合\n",
    "patch_dim = create_patch_whole(return_array_beta,FIL,DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 21025, 5, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_cubes = create_patch_cube(patch_dim,FIL, DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21025, 5, 5, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_cubes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_labels = out.reshape(145*145,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lable_array = useful_sample_lable(patch_cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10249, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lable_array.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lable_array[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sample_label(sample_lable_array,'F:\\data\\sample_lable_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = load_sample_label('F:\\data\\sample_lable_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10249, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.array([whole_data[:,0][i]for i in range(whole_data.shape[0])])  ## 取出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lable = sample_lable_array[:,-1] -1 ## 取出标签\n",
    "lable_ = keras.utils.to_categorical(Lable,num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10249, 5, 5, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, lable_train, lable_test = train_test_split(Data,lable_,test_size=0.8) ## 分割训练测试集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.shape\n",
    "data_train = data_train.reshape(2049,5,5,200,1)\n",
    "#data_train = data_train.reshape(1024,5,5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 5, 5, 200, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 200, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.shape\n",
    "data_test = data_test.reshape(8200, 5, 5, 200,1)\n",
    "#data_test = data_test.reshape(9225,5,5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 5, 5, 200, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------------------\n",
      "Epoch 1/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 1.5934 - acc: 0.4895\n",
      "Epoch 2/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 1.0518 - acc: 0.6164\n",
      "Epoch 3/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 0.8738 - acc: 0.6906\n",
      "Epoch 4/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 0.6923 - acc: 0.7531\n",
      "Epoch 5/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 0.5793 - acc: 0.7940 3s - loss: 0.5\n",
      "Epoch 6/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 0.4653 - acc: 0.8263\n",
      "Epoch 7/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 0.3882 - acc: 0.8507: 0s - loss: 0.3887 - acc: 0.\n",
      "Epoch 8/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 0.3164 - acc: 0.8848\n",
      "Epoch 9/100\n",
      "2049/2049 [==============================] - 31s 15ms/step - loss: 0.3054 - acc: 0.8882\n",
      "Epoch 10/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 0.2281 - acc: 0.9161\n",
      "Epoch 11/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.2010 - acc: 0.9292\n",
      "Epoch 12/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1710 - acc: 0.9380\n",
      "Epoch 13/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1495 - acc: 0.9488\n",
      "Epoch 14/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1199 - acc: 0.9600\n",
      "Epoch 15/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1201 - acc: 0.9595\n",
      "Epoch 16/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0656 - acc: 0.9780\n",
      "Epoch 17/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1089 - acc: 0.9663\n",
      "Epoch 18/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.6581 - acc: 0.8458\n",
      "Epoch 19/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1642 - acc: 0.9478\n",
      "Epoch 20/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.1164 - acc: 0.9610\n",
      "Epoch 21/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0908 - acc: 0.9678\n",
      "Epoch 22/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0744 - acc: 0.9736\n",
      "Epoch 23/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0624 - acc: 0.9795\n",
      "Epoch 24/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0699 - acc: 0.9785\n",
      "Epoch 25/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0506 - acc: 0.9824\n",
      "Epoch 26/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0357 - acc: 0.9898\n",
      "Epoch 27/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0127 - acc: 0.9980\n",
      "Epoch 28/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0091 - acc: 0.9985\n",
      "Epoch 29/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 9.3088e-04 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 6.7918e-04 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "2049/2049 [==============================] - 28s 13ms/step - loss: 5.9665e-04 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "2049/2049 [==============================] - 26s 13ms/step - loss: 5.1710e-04 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "2049/2049 [==============================] - 28s 13ms/step - loss: 4.5993e-04 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "2049/2049 [==============================] - 26s 13ms/step - loss: 4.2561e-04 - acc: 1.0000 3s - loss: 3.9205\n",
      "Epoch 36/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 5.3820e-04 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "2049/2049 [==============================] - 26s 12ms/step - loss: 3.5770e-04 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 3.3072e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 3.1017e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "2049/2049 [==============================] - 25s 12ms/step - loss: 2.9100e-04 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "2049/2049 [==============================] - 26s 12ms/step - loss: 2.7549e-04 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 2.6063e-04 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 2.4587e-04 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 2.3541e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 2.2492e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 2.1579e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 2.0884e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 2.0124e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 1.9270e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.8508e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.7865e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.7444e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 1.6888e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 1.6371e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 1.5733e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 1.5316e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.4944e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 1.4555e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.4213e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.3882e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.3497e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.3123e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.2887e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.2581e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 1.2297e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.3101e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "2049/2049 [==============================] - 30s 14ms/step - loss: 1.1794e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.1536e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.1337e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.1077e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.0840e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.0653e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.0451e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 1.0234e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 1.0043e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 9.8868e-05 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 9.7165e-05 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "2049/2049 [==============================] - 31s 15ms/step - loss: 9.5336e-05 - acc: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049/2049 [==============================] - 30s 14ms/step - loss: 9.3893e-05 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 9.2417e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 9.0914e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 8.9174e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 8.7982e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 8.6863e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "2049/2049 [==============================] - 30s 15ms/step - loss: 8.5231e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 8.3898e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 8.2485e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "2049/2049 [==============================] - 29s 14ms/step - loss: 8.1329e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "2049/2049 [==============================] - 28s 13ms/step - loss: 8.0365e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.9125e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.8164e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "2049/2049 [==============================] - 28s 13ms/step - loss: 7.7136e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.5982e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.5043e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.4007e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 7.3000e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "2049/2049 [==============================] - 28s 14ms/step - loss: 7.2052e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.1280e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "2049/2049 [==============================] - 27s 13ms/step - loss: 7.0174e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "2049/2049 [==============================] - 28s 13ms/step - loss: 6.9643e-05 - acc: 1.0000\n",
      "Tseting -------------------------\n",
      "8200/8200 [==============================] - 38s 5ms/step\n",
      "\n",
      "test loss:  0.2591673172326933\n",
      "\n",
      "test accuracy 0.9529268292682926\n"
     ]
    }
   ],
   "source": [
    "#### --------------------------------放入云服务器计算-----------------------------------------######\n",
    "print('Training ------------------------')\n",
    "model.fit(data_train, lable_train, batch_size=16, epochs=100)\n",
    "print('Tseting -------------------------')\n",
    "score = model.evaluate(data_test, lable_test, batch_size=16)\n",
    "print('\\ntest loss: ', score[0])\n",
    "print('\\ntest accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dcnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
